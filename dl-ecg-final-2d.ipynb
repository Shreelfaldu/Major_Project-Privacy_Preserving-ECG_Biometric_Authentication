{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1490938,"sourceType":"datasetVersion","datasetId":875281}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","metadata":{"_uuid":"0bee7efb-3cd9-4862-9843-4763514fecec","_cell_guid":"48ee12f1-78d1-4708-a1cf-a8bf50054e70","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T04:14:34.091167Z","iopub.execute_input":"2024-12-17T04:14:34.091949Z","iopub.status.idle":"2024-12-17T04:14:46.751452Z","shell.execute_reply.started":"2024-12-17T04:14:34.091905Z","shell.execute_reply":"2024-12-17T04:14:46.750733Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure GPU is being used\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if tf.config.list_physical_devices('GPU'):\n        return \"/GPU:0\"\n    else:\n        return \"/CPU:0\"\n\ndevice = get_default_device()\nprint(f\"Using device: {device}\")\n\n# For TPU\n# try:\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n#     print(f\"Running on TPU: {tpu.master()}\")\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     strategy = tf.distribute.TPUStrategy(tpu)\n# except ValueError:\n#     print(\"TPU not found. Falling back to CPU/GPU.\")\n#     strategy = tf.distribute.get_strategy()  # Use default strategy\n\n# print(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:14:46.753114Z","iopub.execute_input":"2024-12-17T04:14:46.753727Z","iopub.status.idle":"2024-12-17T04:14:47.006453Z","shell.execute_reply.started":"2024-12-17T04:14:46.753686Z","shell.execute_reply":"2024-12-17T04:14:47.005310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = '../input/ecg-image-data/ECG_Image_data/train'\ntest_path = '../input/ecg-image-data/ECG_Image_data/train'","metadata":{"_uuid":"76031696-704a-4292-8ee0-e47b4977100c","_cell_guid":"ffffa5b0-4f3e-4195-addf-8a7119c99820","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T04:14:50.487637Z","iopub.execute_input":"2024-12-17T04:14:50.488284Z","iopub.status.idle":"2024-12-17T04:14:50.492511Z","shell.execute_reply.started":"2024-12-17T04:14:50.488240Z","shell.execute_reply":"2024-12-17T04:14:50.491442Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_classes = os.listdir(train_path)\nclasses_to_include = [cls for cls in all_classes if cls != \"F\"]\n\n# Data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\ntrain_df = train_datagen.flow_from_directory(train_path,\n                                             target_size=(224, 224),\n                                             batch_size=32,\n                                             class_mode='categorical',\n                                             classes=classes_to_include)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_df = test_datagen.flow_from_directory(test_path,\n                                           target_size=(224, 224),\n                                           batch_size=32,\n                                           class_mode='categorical',\n                                           classes=classes_to_include)\n","metadata":{"_uuid":"a48b6948-8e35-4707-9a43-8d8215b7523f","_cell_guid":"38ac3000-b485-48f8-b7d9-cf5cb8255f7a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T04:14:50.839123Z","iopub.execute_input":"2024-12-17T04:14:50.839477Z","iopub.status.idle":"2024-12-17T04:18:18.684375Z","shell.execute_reply.started":"2024-12-17T04:14:50.839445Z","shell.execute_reply":"2024-12-17T04:18:18.683616Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Count_Samples(dataset_path):\n    class_counts = {}\n    for class_name in os.listdir(dataset_path):\n        class_folder = os.path.join(dataset_path, class_name)\n        if os.path.isdir(class_folder):\n            class_counts[class_name] = len(os.listdir(class_folder))\n    \n    # Create the pie chart\n    plt.figure(figsize=(8, 8))\n    plt.pie(class_counts.values(), labels=class_counts.keys(), autopct='%1.1f%%', startangle=140)\n    plt.title(f\"Distribution of ECG Classes in both Train and Test Sets\")\n    plt.axis('equal')   \n    plt.show()\n\nCount_Samples(train_path)","metadata":{"_uuid":"8ee04f44-4eeb-4ec2-9960-fc40758f6610","_cell_guid":"d7d8de13-059a-4950-ba99-4a68b2520840","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-17T04:18:18.685703Z","iopub.execute_input":"2024-12-17T04:18:18.685961Z","iopub.status.idle":"2024-12-17T04:18:18.984666Z","shell.execute_reply.started":"2024-12-17T04:18:18.685936Z","shell.execute_reply":"2024-12-17T04:18:18.983331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Building","metadata":{"_uuid":"ed4034b1-8303-4a22-95bc-84f2c7b94ea3","_cell_guid":"1cdbaa07-348f-4d1a-9aef-ecfc375181fa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def build_2d_cnn(input_shape, num_classes):\n    model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    GlobalAveragePooling2D(),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(num_classes, activation='softmax')\n    ])\n    model.compile(optimizer=Adam(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n    return model\n\ndef build_vgg16(input_shape, num_classes):\n    model = Sequential([\n        # Block 1\n        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n        Conv2D(32, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n\n        # Block 2\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n\n        # Block 3\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n\n        GlobalAveragePooling2D(),   \n        Dense(64, activation='relu'),   \n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')   \n    ])\n    \n    model.compile(optimizer=Adam(learning_rate=0.001), \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    return model\n\ndef build_vgg19(input_shape, num_classes):\n    model = Sequential([\n        # Convolutional Block 1\n        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n        \n        # Convolutional Block 2\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n        \n        # Convolutional Block 3\n        Conv2D(256, (3, 3), activation='relu', padding='same'),\n        Conv2D(256, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n        \n        # Global pooling and Dense layers\n        GlobalAveragePooling2D(),\n        Dense(64, activation='relu'),  \n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')   \n    ])\n\n    model.compile(optimizer=Adam(),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model\n\n\ndef build_resnet50(input_shape, num_classes):\n    model = Sequential([\n        \n        # Initial Convolutional Layer\n        Conv2D(64, (7, 7), strides=(2, 2), activation='relu', padding='same', input_shape=input_shape),\n        MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n        \n        # Residual-like Blocks\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n\n        GlobalAveragePooling2D(),\n        Dense(64, activation='relu'),  \n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')  \n    ])\n    model.compile(optimizer=Adam(),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n","metadata":{"_uuid":"fceff413-7761-410a-95e8-ae493f736bfa","_cell_guid":"44eff24f-39c5-489c-a246-d4f8af0cd841","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training function\ndef train_all_models(train_df, test_df):\n    IMAGE_SIZE = (224, 224, 3)\n    model_configs = [\n        {'type': '2d_cnn', 'func': build_2d_cnn}\n        {'type': 'vgg16', 'func': build_vgg16},\n        {'type': 'vgg19', 'func': build_vgg19},\n        {'type': 'resnet50', 'func': build_resnet50},\n    ]\n    \n    model_results = {}\n    for config in model_configs:\n        print(f\"\\n--- Training {config['type']} Model ---\")\n        # with strategy.scope():  # Use TPU distribution strategy\n        model = config['func']((224, 224, 3), len(classes_to_include))\n        model.summary()\n        history = model.fit(train_df,\n                            validation_data=test_df,\n                            epochs=10,\n                            verbose=1)\n        test_loss, test_accuracy = model.evaluate(test_df)\n        print(f\"Test Loss: {test_loss}\")\n        print(f\"Test Accuracy: {test_accuracy}\")\n        model_results[config['type']] = {'history': history}\n    return model_results","metadata":{"_uuid":"c75fb6aa-83eb-4903-a9fb-ce9279f93946","_cell_guid":"443f0c74-8569-4853-b4f0-98e3fd7f41b1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T04:18:19.004510Z","iopub.execute_input":"2024-12-17T04:18:19.005296Z","iopub.status.idle":"2024-12-17T04:18:19.017796Z","shell.execute_reply.started":"2024-12-17T04:18:19.005245Z","shell.execute_reply":"2024-12-17T04:18:19.016996Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_model_comparisons(model_results):\n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 2, 1)\n    for model_name, results in model_results.items():\n        plt.plot(results['history'].history['val_accuracy'], label=model_name)\n    plt.title('Model Accuracy Comparison')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    for model_name, results in model_results.items():\n        plt.plot(results['history'].history['val_loss'], label=model_name)\n    plt.title('Model Loss Comparison')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()","metadata":{"_uuid":"4968a25c-9f16-4b69-8432-09e3089f350f","_cell_guid":"7cbf3026-8aad-46c2-98d6-553311df7959","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-17T04:18:19.018698Z","iopub.execute_input":"2024-12-17T04:18:19.018945Z","iopub.status.idle":"2024-12-17T04:18:19.032995Z","shell.execute_reply.started":"2024-12-17T04:18:19.018921Z","shell.execute_reply":"2024-12-17T04:18:19.032150Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = train_all_models(train_df, test_df)\nplot_model_comparisons(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:24:31.342940Z","iopub.execute_input":"2024-12-17T04:24:31.343893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nimport numpy as np\n\nmodel_2d_cnn = build_2d_cnn((224, 224, 3), len(classes_to_include))  \nmodel_vgg16 = build_vgg16((224, 224, 3), len(classes_to_include))    \nmodel_vgg19 = build_vgg19((224, 224, 3), len(classes_to_include))    \nmodel_resnet50 = build_resnet50((224, 224, 3), len(classes_to_include)) \n\n# Assuming models are trained, load their weights if needed:\n# model_2d_cnn.load_weights('model_2d_cnn.h5')\n# model_vgg16.load_weights('model_vgg16.h5')\n# model_vgg19.load_weights('model_vgg19.h5')\n# model_resnet50.load_weights('model_resnet50.h5')\n\ndef ensemble_predict(models, test_generator, weights=None):\n    num_models = len(models)\n    num_samples = test_generator.samples\n    num_classes = len(classes_to_include)\n\n    ensemble_preds = np.zeros((num_samples, num_classes))\n    if weights is None:\n        weights = [1 / num_models] * num_models\n\n    for model, weight in zip(models, weights):\n        preds = model.predict(test_generator, verbose=0)\n        ensemble_preds += weight * preds\n\n    return ensemble_preds\n\n# Evaluate ensemble predictions\nmodels = [model_2d_cnn, model_vgg16, model_vgg19, model_resnet50]\nweights = [0.25, 0.25, 0.25, 0.25]  # Equal weights for simplicity\nensemble_preds = ensemble_predict(models, test_df, weights)\nensemble_classes = np.argmax(ensemble_preds, axis=1)\ntrue_classes = test_df.classes\n\n# Accuracy\naccuracy = np.sum(ensemble_classes == true_classes) / len(true_classes)\nprint(f\"Ensemble Accuracy: {accuracy:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}